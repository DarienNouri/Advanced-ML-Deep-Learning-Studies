{"cells":[{"cell_type":"markdown","metadata":{"id":"OMAdi9qgC-B9"},"source":["To copy this template: File -> Save a Copy in Drive\n","\n","***DISCLAIMER**: In case of any discrepancy in the assignment instruction, please refer to the `PDF` document.*"]},{"cell_type":"markdown","metadata":{"id":"eMQTvS1Xe0qI"},"source":["# BERT for question answering & Finetuning "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"F354fAtdZUD7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (0.21.3)\n","Requirement already satisfied: numpy>=1.17 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (0.15.2)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n","Requirement already satisfied: tqdm>=4.27 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/darien/miniforge3/envs/EnvKeras/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n","Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading safetensors-0.4.2-cp311-cp311-macosx_11_0_arm64.whl (393 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.4/393.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: safetensors, transformers\n","Successfully installed safetensors-0.4.2 transformers-4.39.3\n"]}],"source":["# Install the transformers library that will be used for BERT models.\n","!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"GC0n5NpjmC9q"},"source":["## 4.1 **(1)**\n","\n","We will use the BertForQuestionAnswering model and the BertTokenizer as our tokenizer."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch\n","  Downloading torch-2.2.2-cp39-none-macosx_11_0_arm64.whl.metadata (25 kB)\n","Collecting torchvision\n","  Downloading torchvision-0.17.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n","Collecting torchaudio\n","  Downloading torchaudio-2.2.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n","Requirement already satisfied: filelock in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torch) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torch) (4.11.0)\n","Collecting sympy (from torch)\n","  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n","Collecting networkx (from torch)\n","  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: jinja2 in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torch) (2024.2.0)\n","Requirement already satisfied: numpy in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torchvision) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from torchvision) (10.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/darien/miniforge3/envs/transformers-env/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n","Collecting mpmath>=0.19 (from sympy->torch)\n","  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n","Downloading torch-2.2.2-cp39-none-macosx_11_0_arm64.whl (59.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading torchvision-0.17.2-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.2.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hUsing cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n","Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n","Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n","Installing collected packages: mpmath, sympy, networkx, torch, torchvision, torchaudio\n","Successfully installed mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2\n"]}],"source":["!pip3 install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"TGSwHinfZWWB"},"outputs":[],"source":["import torch\n","from transformers import BertForQuestionAnswering\n","from transformers import BertTokenizer\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["\n","#Get the pretrained 'bert-large-uncased-whole-word-masking-finetuned-squad' model from the BertForQuestionAnswering library\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","\n","'''TO DO:\n","\n","# Similarly, get the tokenizer from pretrained 'bert-large-uncased-whole-word-masking-finetuned-squad' from the BertTokenizer library.\n","\n","'''\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"]},{"cell_type":"markdown","metadata":{"id":"496t95IZfy4W"},"source":["We define the question as well as the textual paragraph which the question is based on.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gjEgnTaPZZ3o"},"outputs":[],"source":["question = \"What was BERT trained on?\"\n","\n","paragraph = \"BERT stands for Bidirectional Encoder Representation of Transformer. I feel that its name itself is descriptive enough to get the gist. Still, to understand it better, it’s encoder part of the encoder-decoder transformer model, it’s also bidirectional in nature, which means that for any input it’s able to learn dependencies from both left and right of any word. It was trained on Wikipedia text and BooksCorpus and open-sourced back in 2018 by Google. You can find the official repository and paper at Github: BERT and BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. There are two models introduced in the paper. BERT base — 12 layers (transformer blocks), 110 million parameters. BERT Large — 24 layers, 340 million parameters. Later google also released Multi-lingual BERT to accelerate the research\""]},{"cell_type":"markdown","metadata":{"id":"iiSOz6d6lIGS"},"source":["## 4.2 **(2)**\n","\n","Use the encode_plus function. Define the text parameter as the question, and the text_pair as the paragraph.\n","\n","You can refer to: https://huggingface.co/docs/transformers/v4.19.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qoGMtVTFf7es"},"outputs":[],"source":["encoding = tokenizer.encode_plus(text= question , text_pair=paragraph, add_special_tokens=True)"]},{"cell_type":"markdown","metadata":{"id":"fYDOwox4lOEr"},"source":["## 4.3 **(2)**\n","\n","The encoding is a dictionary with multiple keys. Your task is to identify which keys will be used for the inputs and which will be used for the segment embeddings."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"5QjwwO-DiFbB"},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"]}],"source":["print(encoding.keys())"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"H83wEfuNiMY0"},"outputs":[],"source":["\"\"\"TO DO\"\"\"\n","\n","inputs = encoding['input_ids']  #Token embeddings\n","\n","sentence_embedding = encoding['token_type_ids'] #Segment embeddings\n","\n","\n","# we convert the input ids to tokens\n","tokens = tokenizer.convert_ids_to_tokens(inputs) #input tokens"]},{"cell_type":"markdown","metadata":{"id":"4pNCHcSrkWTt"},"source":["The model returns the most probable start and end words scores."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"_JNbTmNGZhI5"},"outputs":[{"name":"stdout","output_type":"stream","text":["QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-5.4397, -5.1747, -8.2072, -8.1577, -7.4659, -6.3724, -9.4946, -5.4397,\n","         -1.1487, -5.9532, -7.5790, -2.0921, -7.5579, -7.1692, -7.1343, -4.7308,\n","         -6.7858, -7.5462, -5.3032, -7.8723, -5.3115, -7.4651, -7.9509, -6.8902,\n","         -7.9474, -8.6392, -6.2064, -7.5566, -8.5925, -8.2583, -6.7350, -8.4192,\n","         -8.4794, -7.7465, -8.4259, -7.5299, -8.5404, -9.1108, -7.8087, -8.6896,\n","         -7.1670, -7.7759, -8.2495, -8.5528, -8.7607, -5.9098, -8.4287, -8.4879,\n","         -6.4561, -7.5364, -8.4136, -6.9562, -8.3993, -6.9945, -4.6695, -6.9653,\n","         -7.7577, -7.9944, -5.2502, -7.7105, -5.6726, -8.0013, -5.9588, -8.3135,\n","         -6.2524, -8.2741, -8.4364, -8.1030, -3.8497, -8.1456, -8.0798, -8.2123,\n","         -8.8444, -7.8705, -8.4785, -7.6194, -7.5587, -8.2160, -6.8581, -6.2673,\n","         -5.9076, -6.9228, -8.1743, -8.5033, -6.8941, -7.6130, -6.1818, -6.1809,\n","         -7.9185, -8.4507, -7.5275, -7.6268, -8.8922, -7.7156, -8.6203, -7.1086,\n","         -6.1379, -5.4391,  3.0556, -1.8654,  0.2161,  1.8502,  7.0433, -0.0623,\n","         -3.3860,  0.3552, -4.4067, -4.3378, -5.0077, -2.3701, -7.7126, -5.4115,\n","         -6.0636, -7.1311, -3.8632, -6.5843, -2.5213, -5.3629, -5.4489, -7.9564,\n","         -6.9294, -6.5368, -5.8804, -6.1871, -8.1388, -5.4989, -7.6130, -4.0434,\n","         -7.9005, -6.8704, -8.1771, -4.0541, -8.0120, -4.8147, -7.6088, -4.7567,\n","         -8.5856, -5.8299, -7.3574, -2.4655, -3.5056, -7.4083, -7.1332, -6.8330,\n","         -3.5799, -6.2535, -2.7920, -6.0227, -6.9585, -7.1037, -8.6158, -7.1637,\n","         -6.8444, -8.1453, -8.6788, -8.0549, -7.1728, -8.2049, -4.3319, -6.5721,\n","         -8.2553, -5.6758, -7.3268, -7.8970, -6.0569, -8.6976, -8.0074, -8.8972,\n","         -8.6795, -6.9268, -8.2060, -7.4203, -7.0254, -4.4198, -6.4294, -8.2077,\n","         -6.3953, -7.8963, -8.9824, -7.9377, -8.6474, -7.7518, -6.9449, -7.1425,\n","         -5.6089, -8.7612, -7.3994, -4.5860, -8.6494, -8.0245, -8.4521, -6.1071,\n","         -8.5307, -8.3045, -9.2553, -7.7841, -5.4397]],\n","       grad_fn=<CloneBackward0>), end_logits=tensor([[-2.3962, -6.0587, -7.3123, -7.9339, -7.8669, -6.4033, -7.8505, -2.3961,\n","         -1.5374, -6.5057, -6.9857, -5.3008, -6.4160, -6.3407, -5.1260, -5.7924,\n","         -6.0060, -5.0599, -4.0462, -6.0150, -5.0006, -2.4412, -2.8137, -7.0935,\n","         -7.5557, -7.8545, -7.3459, -6.8046, -7.5698, -7.9834, -6.5760, -7.0411,\n","         -8.1462, -8.0507, -8.0474, -7.7215, -6.0286, -7.1719, -7.6960, -6.6701,\n","         -8.3963, -7.6997, -7.3218, -7.1375, -7.0923, -7.3704, -7.6311, -7.8357,\n","         -7.9933, -7.4045, -7.2620, -7.1427, -7.8421, -7.8382, -6.6159, -6.4786,\n","         -5.5269, -7.9525, -5.9952, -4.1659, -6.5612, -4.4616, -3.6847, -5.4864,\n","         -7.4989, -7.4729, -7.6456, -8.1858, -5.8829, -7.0872, -7.1690, -5.4062,\n","         -7.5727, -5.4646, -5.5943, -7.9502, -7.8006, -7.9409, -8.0511, -7.0104,\n","         -4.2649, -7.2826, -7.1577, -7.7684, -7.7243, -7.8916, -6.8411, -6.6768,\n","         -5.3702, -7.8976, -7.6877, -6.8084, -7.9347, -5.9796, -7.6542, -7.2234,\n","         -3.4666, -2.3972, -4.0655, -5.8383, -3.7694, -3.6949,  3.3461,  3.9657,\n","         -2.6179,  0.5853, -0.8846,  5.9375,  1.0804, -4.8448, -5.5675, -0.0562,\n","         -3.0940, -6.1710, -0.7458, -5.7990,  0.4638,  2.6418, -7.1250, -7.7189,\n","         -7.6161, -7.6129, -7.0730, -5.1305, -8.1973, -5.7736, -8.0792, -6.2630,\n","         -6.8132, -3.1355, -7.2717, -3.9339, -8.1074, -5.8786, -7.8542, -7.0955,\n","         -8.0806, -5.4364, -7.8141, -5.5754, -6.3522, -7.2444, -7.2551, -6.5714,\n","         -2.1189, -7.5243, -3.3398, -1.5684, -3.3382, -8.1540, -8.4593, -7.7807,\n","         -5.9308, -7.7073, -8.6030, -8.1073, -6.3326, -7.4856, -5.7868, -5.4412,\n","         -7.8095, -7.0012, -4.9758, -8.6179, -7.6053, -7.0444, -6.2096, -6.4916,\n","         -8.1871, -8.3490, -7.3522, -4.6738, -4.1927, -5.9938, -4.6736, -7.3120,\n","         -7.3557, -5.4430, -7.9541, -8.3317, -7.1188, -4.3462, -4.1785, -7.6377,\n","         -6.7526, -8.1466, -7.7143, -6.5898, -8.0528, -6.6152, -4.8945, -3.7080,\n","         -7.8381, -7.8626, -7.7298, -6.0289, -2.3963]],\n","       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"]}],"source":["scores = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n","print(scores)"]},{"cell_type":"markdown","metadata":{"id":"9oiSHY6dlpYc"},"source":["## 4.4 **(2)**\n","\n","Now we have start scores and end scores we can get both the start index and the end index and use both the indices for span prediction."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"flz6aht7ZvRb"},"outputs":[],"source":["\"\"\"\n","TO DO:\n","\n","Use torch.argmax to get the indices for the start and end words with the highest probability.\n","\n","Use scores.start_logits and scores.end_logits\n","\n","\"\"\"\n","\n","start_index = torch.argmax(scores.start_logits)\n","\n","end_index = torch.argmax(scores.end_logits)\n","\n","\n","if end_index >= start_index:\n","    get = \" \".join(tokens[start_index:end_index+1])\n","else:\n","    print(\"I am unable to find the answer to this question. Can you please ask another question?\")"]},{"cell_type":"markdown","metadata":{"id":"5LpF2RV9mc5i"},"source":["## 4.5 **(1)**\n","Display the answer given by the model."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"_2K9R4rlZ0E0"},"outputs":[{"name":"stdout","output_type":"stream","text":["wikipedia text and books ##corp ##us\n"]}],"source":["\"\"\" to do: print output \"\"\"\n","print(get)"]},{"cell_type":"markdown","metadata":{"id":"XsIBMx3vlaJV"},"source":["## 4.6 **(2)**\n","\n","Did you see any unusual tokens in the answer? What could be the reason for that?"]},{"cell_type":"markdown","metadata":{"id":"EeaCqPUYldcf"},"source":["**Answer**: There are some unusual tokens in the answer. The reason for this is that for words not in its feature set, the bert tokenizer parses them into smaller subwords which are marked by `#` character. In this case, the word `bookscorpus` was not in the feature set of the tokenizer, so it was parsed into smaller subwords `book` and `##corp` `##us`."]}],"metadata":{"colab":{"provenance":[{"file_id":"1SGA4jOi9BXt8BagvvrYVBSMrwVmCWSmE","timestamp":1699398421717},{"file_id":"1fpZWNYTtKAbY-fnPAB-pnLhAERO87WDN","timestamp":1678057366053},{"file_id":"1djEl5L2KEdnl1C8cv1SbZCH__riuV-c9","timestamp":1652420174559},{"file_id":"1MJ6L11lyMYnBiclT0jEq8gAPGbA30Xet","timestamp":1652418114500},{"file_id":"1vXsUbRaqICsnuOOOyaPEuE7pNHidZs-g","timestamp":1652397667216}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
